# -*- coding: utf-8 -*-
"""SoulPage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bNQtMkosdWOz89Ds2OY0DcshK-vcvHTP
"""

pip install numpy pandas matplotlib tensorflow keras opencv-python pillow

import os
import zipfile
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# Merge the dataframes on 'img_id'
combined_annotations = pd.merge(annotations_1, annotations_2, on='img_id')
print(combined_annotations.head())

import os

# Check the contents of the extracted directories
extract_dir_1 = '/content/Licplatesrecognition_train/license_plates_recognition_train'
extract_dir_2 = '/content/Licplatesdetection_train/license_plates_detection_train'
extract_dir_test = '/content/test/test/test'

print("Contents of Licplatesrecognition_train:", os.listdir(extract_dir_1)[:10])
print("Contents of Licplatesdetection_train:", os.listdir(extract_dir_2)[:10])
print("Contents of test:", os.listdir(extract_dir_test)[:10])

# Display the first few rows of the CSV files to ensure they are correctly loaded
print("Annotations 1 Head:")
print(annotations_1.head())

print("Annotations 2 Head:")
print(annotations_2.head())

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os

# Load the CSV files
annotations_1 = pd.read_csv('/content/Licplatesrecognition_train.csv')
annotations_2 = pd.read_csv('/content/Licplatesdetection_train.csv')

# Merge the annotations data on 'img_id'
combined_annotations = pd.merge(annotations_1, annotations_2, on='img_id')

# Function to load images, bounding boxes, and text from the specified folder
def load_images_boxes_text(image_folder, annotations, img_size=(224, 224)):
    images = []
    boxes = []
    texts = []
    for idx, row in annotations.iterrows():
        img_id = row['img_id']
        img_path = os.path.join(image_folder, img_id)
        print(f"Attempting to load image from: {img_path}")
        image = cv2.imread(img_path)
        if image is not None:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = cv2.resize(image, img_size)  # Resize image to a fixed size
            images.append(image)
            box = [row['ymin'], row['xmin'], row['ymax'], row['xmax']]
            boxes.append(box)
            texts.append(row['text'])
        else:
            print(f"Image not found or unable to read at {img_path}")
    return np.array(images), np.array(boxes), np.array(texts)

# Assuming the images are stored in the following paths
extract_dir_1 = '/content/Licplatesrecognition_train/license_plates_recognition_train'
extract_dir_2 = '/content/Licplatesdetection_train/license_plates_detection_train'

# Load the images, bounding boxes, and text from the combined annotations
train_images, train_boxes, train_texts = load_images_boxes_text(extract_dir_2, combined_annotations)

# Verify the loaded data
print(f"Loaded {len(train_images)} images, {len(train_boxes)} bounding boxes, and {len(train_texts)} texts.")

# Display a sample image with bounding box
if len(train_images) > 0:
    sample_image = train_images[0]
    sample_box = train_boxes[0]
    ymin, xmin, ymax, xmax = sample_box
    cv2.rectangle(sample_image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)
    plt.imshow(sample_image)
    plt.title('Sample Image with Bounding Box')
    plt.show()
else:
    print("No images to display.")

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(train_images, train_texts, test_size=0.2, random_state=42)

# Dummy model to generate random predictions (replace with actual model)
def dummy_model_predict(images):
    predictions = []
    for img in images:
        pred_text = ''.join(np.random.choice(list('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'), 7))
        predictions.append(pred_text)
    return predictions

# Make predictions on the validation set
val_predictions = dummy_model_predict(X_val)

# Create a DataFrame for the results
results_df = pd.DataFrame({
    'id': [f'img_{i+901}' for i in range(len(val_predictions))],
    '0': [char if len(char) > 0 else '' for char in val_predictions],
    '1': ['' for _ in range(len(val_predictions))],
    '2': ['' for _ in range(len(val_predictions))],
    '3': ['' for _ in range(len(val_predictions))],
    '4': ['' for _ in range(len(val_predictions))],
    '5': ['' for _ in range(len(val_predictions))],
    '6': ['' for _ in range(len(val_predictions))],
    '7': ['' for _ in range(len(val_predictions))],
    '8': ['' for _ in range(len(val_predictions))],
    '9': ['' for _ in range(len(val_predictions))]
})

# Save the results to a CSV file
results_df.to_csv('/content/SampleSubmission.csv', index=False)
print("Results saved to SampleSubmission.csv")

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Normalize image data
X_train = X_train / 255.0
X_val = X_val / 255.0

# Combine text data for encoding
combined_text = np.concatenate((y_train, y_val))

# Encode text data
label_encoder = LabelEncoder()
label_encoder.fit(combined_text)
y_train_encoded = label_encoder.transform(y_train)
y_val_encoded = label_encoder.transform(y_val)

# Convert labels to categorical (one-hot encoding)
num_classes = len(label_encoder.classes_)
y_train_encoded = to_categorical(y_train_encoded, num_classes)
y_val_encoded = to_categorical(y_val_encoded, num_classes)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Define a simple CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Fit the model
batch_size = 32
epochs = 20

history = model.fit(datagen.flow(X_train, y_train_encoded, batch_size=batch_size),
                    validation_data=(X_val, y_val_encoded),
                    epochs=epochs,
                    verbose=1)

def display_images_with_boxes(images, boxes, count=5):
    for i in range(min(count, len(images))):
        plt.figure(figsize=(10, 10))
        plt.imshow(images[i])
        ymin, xmin, ymax, xmax = boxes[i]
        plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, edgecolor='red', facecolor='none'))
        plt.show()

display_images_with_boxes(train_images, train_boxes)

from sklearn.preprocessing import LabelEncoder

# Flatten the texts to get all unique characters
all_characters = ''.join(train_texts)
unique_characters = sorted(set(all_characters))

# Encode characters as integers
char_encoder = LabelEncoder()
char_encoder.fit(list(unique_characters))

# Function to encode a license plate text
def encode_text(text):
    return char_encoder.transform(list(text))

# Function to decode a sequence of integers to text
def decode_text(encoded_text):
    return ''.join(char_encoder.inverse_transform(encoded_text))

# Encode all the texts
encoded_texts = [encode_text(text) for text in train_texts]

# Print some examples
for i in range(5):
    print(f"Original: {train_texts[i]}, Encoded: {encoded_texts[i]}")

from tensorflow.keras.preprocessing.sequence import pad_sequences

# Determine the maximum length of the texts
max_length = max(len(text) for text in encoded_texts)

# Pad the sequences so they all have the same length
padded_texts = pad_sequences(encoded_texts, maxlen=max_length, padding='post')

# Convert padded texts to categorical
num_classes = len(char_encoder.classes_)
categorical_texts = [to_categorical(text, num_classes=num_classes) for text in padded_texts]

# Convert categorical texts to a numpy array
y = np.array(categorical_texts)

# Verify the shapes of the arrays
print(f"Shape of X: {X.shape}")
print(f"Shape of y: {y.shape}")

from sklearn.model_selection import train_test_split

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Shape of X_train: {X_train.shape}")
print(f"Shape of y_train: {y_train.shape}")
print(f"Shape of X_val: {X_val.shape}")
print(f"Shape of y_val: {y_val.shape}")

# Save the model
model.save('license_plate_recognition_model.keras')

# Evaluate the model
loss, accuracy = model.evaluate(X_val, y_val)
print(f"Validation Accuracy: {accuracy * 100:.2f}%")

# Generate predictions
predictions = model.predict(X_val)

# Ensure predictions have the correct shape
print(f"Shape of predictions: {predictions.shape}")

# Convert predictions to text
def decode_prediction(pred):
    return ''.join(char_encoder.inverse_transform(np.argmax(pred, axis=-1)))

predicted_texts = [decode_prediction(pred) for pred in predictions]

# Create a DataFrame for the results
results_df = pd.DataFrame({
    'id': [f'img_{i+1}' for i in range(len(predicted_texts))],
    'text': predicted_texts
})

# Save the results to a CSV file
results_df.to_csv('/content/SampleSubmission.csv', index=False)
print("Results saved to submission.csv")